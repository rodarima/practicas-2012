ALGORITMOS: PRÁCTICA 3.
Rodrigo Arias Mallo; login: rodrigo.arias
Carlos Pérez Ramil; login: c.pramil


Verificación empírica de los análisis de dos algoritmos de ordenación: inserción
y quicksort.


Características de la máquina donde fue realizado el experimento:
	- Procesador Intel(R) Core(TM) i7 CPU Q 720  @ 1.60GHz
	- Memoria RAM 4GB


Realizaremos un  análisis de la eficiencia de dos  algoritmos diferentes para la 
ordenación de vectores. Concretamente, para el experimento utilizaremos vectores
de números enteros. Nos  centraremos  en el estudio de los tiempos de ejecución, 
que serán medidos siempre en microsegundos.

La ordenación  por inserción es iterativa.  Se recorren los elementos del vector
uno a uno, comprobando si el actual es menor que los anteriores hasta dar con su
posición adecuada, donde se "inserta". 

Quicksort, en cambio, es un algoritmo recursivo, y emplea la técnica de divide y
vencerás.  Consiste en  comparar todos los  elementos  del vector con un pivote, 
obteniendo dos nuevos subvectores  (el de los mayores y el de los menores que el
pivote),  y aplicando quicksort de nuevo sobre ellos.  También  establecemos  un
valor umbral que comparamos con el tamaño de los subvectores. Si este  último es
inferior al umbral, no se realizan más llamadas recursivas, y se deja el trabajo
de terminar la ordenación para el algoritmo de inserción. 


	procedimiento Ordenación por inserción (var v[1..n])
		para i := 2 hasta n hacer
			x := v[i] ;
			j := i-1 ;
			mientras j > 0 y v[j] > x hacer
				v[j+1] := v[j] ;
				j := j-1
			fin mientras ;
			v[j+1] := x
		fin para
	fin procedimiento


	-------------------------------------------------------------

	procedimiento OrdenarAux (V[izq..der])
		si izq+UMBRAL <= der entonces
			Mediana3 (V[izq..der]) ;
			pivote := V[izq] ;
			i := izq ;
			j := der ;
			repetir
				repetir i := i + 1 ; hasta V[i] >= pivote ;
				repetir j := j - 1 ; hasta V[j] <= pivote ;
				intercambiar (V[i], V[j]);
			hasta j <= i ;
			intercambiar (V[i], V[j]) ;
			intercambiar (V[izq], V[j]) ;
			OrdenarAux (V[izq..j-1]);
			OrdenarAux (V[j+1..der])
		fin si
	fin procedimiento

	procedimiento Ordenación Rápida (V[1..n])
		OrdenarAux(V[1..n]);
		si (UMBRAL > 1) entonces
			Ordenación por Inserción (V[1..n])
		fin si
	fin procedimiento


Los implementamos en  lenguaje C y  comprobamos que funcionan  correctamente con 
las secuencias de enteros propuestas:


Posteriormente medimos los tiempos de ejecución de los dos algoritmos y tratamos
de hallar sus cotas subestimada, ajustada y sobreestimada. Mediante este proceso
obtenemos las siguientes tablas:

- La primera columna indica el término n-ésimo de la sucesión.
- La segunda columna indica el tiempo de ejecución del algoritmo.
	* En las filas que aparece "k", el tiempo de ejecución es un promedio de
	  k ejecuciones.
- Las cotas están identificadas en las correspondientes columnas.

	
Tabla sumaSubMax1:	h(n) = n^1.8; g(n) = n^2; f(n) = n^2.2

                            SUBESTIMADA       AJUSTADA  SOBREESTIMADA
        n           t(n)      t(n)/h(n)      t(n)/g(n)      t(n)/f(n)        k
      512        717.000       0.009524       0.002735       0.000785
     1024       2728.000       0.010406       0.002602       0.000650
     2048      10506.000       0.011509       0.002505       0.000545
     4096      45898.000       0.014439       0.002736       0.000518
     8192     181129.000       0.016364       0.002699       0.000445
    16384     666166.000       0.017283       0.002482       0.000356
    32768    2678653.000       0.019958       0.002495       0.000312


En esta primera tabla comprobamos que la función h(n) tiene un crecimiento lige-
ramente inferior a t(n),  y por ello la serie generada en la tabla es creciente, 
con lo que deducimos que h(n) es la cota subestimada. 

Por el contrario, la función f(n)  tiene un crecimiento superior al de t(n), con
lo cual la serie de la tabla es decreciente, y f(n) es la cota sobreestimada.

La función g(n) crece de forma similar a t(n), y por tanto los valores de la ta-
bla tienden a una constante de valor 0.0026.  De todas formas,  el cálculo es a-
proximado,  ya que se observan algunos valores  anómalos en la medición,  debido 
por ejemplo a interrupciones del sistema operativo.



Tabla sumaSubMax2: 
h(n) = n * log(n)^0.1; g(n) = n * log(n)^0.57; f(n) = n * log(n)^0.95

                            SUBESTIMADA       AJUSTADA  SOBREESTIMADA
        n           t(n)      t(n)/h(n)      t(n)/g(n)      t(n)/f(n)        k
      512         56.965       0.092647       0.039187       0.019544    10000
     1024        113.600       0.091411       0.036797       0.017632    10000
     2048        239.646       0.095503       0.036760       0.016988    10000
     4096        495.770       0.097931       0.036184       0.016178    10000
     8192       1027.000       0.100624       0.035807       0.015529
    16384       2122.000       0.103188       0.035462       0.014953
    32768       4354.000       0.105135       0.034978       0.014367


Procedemos de forma similar  para analizar  este segundo algoritmo, y observamos
también una cota subestimada -h(n)- y una sobreestimada -f(n)- perfectamente de-
finidas.

En este caso, la cota ajustada g(n) converge hacia 0.035,  a pesar de que se ob-
serva una anomalía en la primera fila de la tabla.


-------------------------------- CONCLUSIONES ----------------------------------

Aunque el primer algoritmo es iterativo,  se puede apreciar claramente la  dife-
rencia de tiempos de  SumaSubMax1  con SumaSubMax2.  Si observamos el tiempo que 
tarda la fila de ambas tablas para el último valor, n=32768, vemos que el primer
algoritmo tarda unos 2,7 segundos en completarse,  mientras que el segundo algo-
ritmo se ejecuta en tan  sólo 4,3 milisegundos.  Por tanto comprobamos que suma-
SubMax2 es claramente más rápido.

